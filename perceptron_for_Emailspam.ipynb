{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "perceptron for Emailspam.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KblrHbHaLUSr"
      },
      "source": [
        "# Email Spam Classification "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7YIY2ChL0Tr"
      },
      "source": [
        "\n",
        "- Dataset\n",
        "\n",
        "https://archive.ics.uci.edu/ml/datasets/Spambase\n",
        "\n",
        "- The dataset description:\n",
        "\n",
        "No null  values\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZV1VHZpNB1d"
      },
      "source": [
        "labels:\n",
        "\n",
        "0:Not Spam \n",
        "\n",
        "1:Spam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe4VWqnvL737"
      },
      "source": [
        "- Algorithms used:\n",
        "\n",
        "Neural network(Perceptron)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XG_Z8fRMYoo"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avKUBOW6rpbi"
      },
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt  \n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2gq3wxDMcpf"
      },
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFz-zN2ar3cG"
      },
      "source": [
        "# Loading dataset into pandas dataframe\n",
        "data = pd.read_csv('/content/spambase.data', names=[x for x in range(58)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "t7OQR4EksR9v",
        "outputId": "d5331551-7ede-420e-a14d-4834395c9d1e"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.29</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.756</td>\n",
              "      <td>61</td>\n",
              "      <td>278</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.28</td>\n",
              "      <td>3.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.16</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.010</td>\n",
              "      <td>9.821</td>\n",
              "      <td>485</td>\n",
              "      <td>2259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0     1     2    3     4     5   ...     52     53     54   55    56  57\n",
              "0  0.00  0.64  0.64  0.0  0.32  0.00  ...  0.000  0.000  3.756   61   278   1\n",
              "1  0.21  0.28  0.50  0.0  0.14  0.28  ...  0.180  0.048  5.114  101  1028   1\n",
              "2  0.06  0.00  0.71  0.0  1.23  0.19  ...  0.184  0.010  9.821  485  2259   1\n",
              "3  0.00  0.00  0.00  0.0  0.63  0.00  ...  0.000  0.000  3.537   40   191   1\n",
              "4  0.00  0.00  0.00  0.0  0.63  0.00  ...  0.000  0.000  3.537   40   191   1\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AixoGNyZMhOH"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idyAtIVKMoNi"
      },
      "source": [
        "- Type of data attributes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8le48vQt8AZn",
        "outputId": "64b134ed-3e6e-42f6-9591-ac28af9ce613"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4601 entries, 0 to 4600\n",
            "Data columns (total 58 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       4601 non-null   float64\n",
            " 1   1       4601 non-null   float64\n",
            " 2   2       4601 non-null   float64\n",
            " 3   3       4601 non-null   float64\n",
            " 4   4       4601 non-null   float64\n",
            " 5   5       4601 non-null   float64\n",
            " 6   6       4601 non-null   float64\n",
            " 7   7       4601 non-null   float64\n",
            " 8   8       4601 non-null   float64\n",
            " 9   9       4601 non-null   float64\n",
            " 10  10      4601 non-null   float64\n",
            " 11  11      4601 non-null   float64\n",
            " 12  12      4601 non-null   float64\n",
            " 13  13      4601 non-null   float64\n",
            " 14  14      4601 non-null   float64\n",
            " 15  15      4601 non-null   float64\n",
            " 16  16      4601 non-null   float64\n",
            " 17  17      4601 non-null   float64\n",
            " 18  18      4601 non-null   float64\n",
            " 19  19      4601 non-null   float64\n",
            " 20  20      4601 non-null   float64\n",
            " 21  21      4601 non-null   float64\n",
            " 22  22      4601 non-null   float64\n",
            " 23  23      4601 non-null   float64\n",
            " 24  24      4601 non-null   float64\n",
            " 25  25      4601 non-null   float64\n",
            " 26  26      4601 non-null   float64\n",
            " 27  27      4601 non-null   float64\n",
            " 28  28      4601 non-null   float64\n",
            " 29  29      4601 non-null   float64\n",
            " 30  30      4601 non-null   float64\n",
            " 31  31      4601 non-null   float64\n",
            " 32  32      4601 non-null   float64\n",
            " 33  33      4601 non-null   float64\n",
            " 34  34      4601 non-null   float64\n",
            " 35  35      4601 non-null   float64\n",
            " 36  36      4601 non-null   float64\n",
            " 37  37      4601 non-null   float64\n",
            " 38  38      4601 non-null   float64\n",
            " 39  39      4601 non-null   float64\n",
            " 40  40      4601 non-null   float64\n",
            " 41  41      4601 non-null   float64\n",
            " 42  42      4601 non-null   float64\n",
            " 43  43      4601 non-null   float64\n",
            " 44  44      4601 non-null   float64\n",
            " 45  45      4601 non-null   float64\n",
            " 46  46      4601 non-null   float64\n",
            " 47  47      4601 non-null   float64\n",
            " 48  48      4601 non-null   float64\n",
            " 49  49      4601 non-null   float64\n",
            " 50  50      4601 non-null   float64\n",
            " 51  51      4601 non-null   float64\n",
            " 52  52      4601 non-null   float64\n",
            " 53  53      4601 non-null   float64\n",
            " 54  54      4601 non-null   float64\n",
            " 55  55      4601 non-null   int64  \n",
            " 56  56      4601 non-null   int64  \n",
            " 57  57      4601 non-null   int64  \n",
            "dtypes: float64(55), int64(3)\n",
            "memory usage: 2.0 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIXn3QpCM8zS"
      },
      "source": [
        "- Shape of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EofwCxVPEKbv",
        "outputId": "57adfd1f-82e2-492c-ae75-7ae1c34bf6c2"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4601, 58)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0ZwxYzf03dK"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "7ps3fCyZ1VmC",
        "outputId": "458bdc1b-a6aa-4e8d-91b1-7a934e893277"
      },
      "source": [
        "a=data[57]\n",
        "b=len(a[a==1])\n",
        "c=len(a[a==0])\n",
        "plt.bar([\"spam\",\"not spam\"],[b,c])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG8Yx1daMtR-"
      },
      "source": [
        "# Selection and training a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbtgnR12sw9i"
      },
      "source": [
        "Y = data[57]\n",
        "del data[57]\n",
        "X = data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLsE_mkOtiZT",
        "outputId": "f6abcea4-ac23-46f4-f369-a6129834112e"
      },
      "source": [
        "Y.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2788\n",
              "1    1813\n",
              "Name: 57, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKhfWXl6s9p-"
      },
      "source": [
        "# Now lets lets split dataset into train and test set using scikit learn\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state=42)\n",
        "# Now using scikit learn lets scale dataset using standardscalar\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBwrR7fXOk9v",
        "outputId": "7fe1fcf3-f768-4846-bacf-84db96759133"
      },
      "source": [
        "len(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1381"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u-owGn1UKSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aad00bc-1e0f-4201-ecb7-6b109bf1078a"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3220, 57)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxiXu7uEq7Wk",
        "outputId": "64301c8a-bef0-43d9-9713-6255f581c90f"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "a=model.fit(X_train,y_train, epochs=200,validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "91/91 [==============================] - 1s 4ms/step - loss: 0.8507 - accuracy: 0.4799 - val_loss: 0.6416 - val_accuracy: 0.6553\n",
            "Epoch 2/200\n",
            "91/91 [==============================] - 0s 1ms/step - loss: 0.6222 - accuracy: 0.6581 - val_loss: 0.5123 - val_accuracy: 0.7950\n",
            "Epoch 3/200\n",
            "91/91 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.8100 - val_loss: 0.4440 - val_accuracy: 0.8696\n",
            "Epoch 4/200\n",
            "91/91 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.8525 - val_loss: 0.4004 - val_accuracy: 0.8820\n",
            "Epoch 5/200\n",
            "91/91 [==============================] - 0s 1ms/step - loss: 0.3839 - accuracy: 0.8790 - val_loss: 0.3728 - val_accuracy: 0.8851\n",
            "Epoch 6/200\n",
            "91/91 [==============================] - 0s 1ms/step - loss: 0.3498 - accuracy: 0.8968 - val_loss: 0.3533 - val_accuracy: 0.8789\n",
            "Epoch 7/200\n",
            "91/91 [==============================] - 0s 1ms/step - loss: 0.3437 - accuracy: 0.8921 - val_loss: 0.3369 - val_accuracy: 0.8851\n",
            "Epoch 8/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.9016 - val_loss: 0.3247 - val_accuracy: 0.8882\n",
            "Epoch 9/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8995 - val_loss: 0.3150 - val_accuracy: 0.8882\n",
            "Epoch 10/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.9054 - val_loss: 0.3066 - val_accuracy: 0.8944\n",
            "Epoch 11/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2963 - accuracy: 0.9087 - val_loss: 0.2986 - val_accuracy: 0.8975\n",
            "Epoch 12/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.9152 - val_loss: 0.2920 - val_accuracy: 0.8975\n",
            "Epoch 13/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.9094 - val_loss: 0.2862 - val_accuracy: 0.9006\n",
            "Epoch 14/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2711 - accuracy: 0.9146 - val_loss: 0.2800 - val_accuracy: 0.9006\n",
            "Epoch 15/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2754 - accuracy: 0.9101 - val_loss: 0.2747 - val_accuracy: 0.9006\n",
            "Epoch 16/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2702 - accuracy: 0.9115 - val_loss: 0.2709 - val_accuracy: 0.9006\n",
            "Epoch 17/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2592 - accuracy: 0.9168 - val_loss: 0.2664 - val_accuracy: 0.9037\n",
            "Epoch 18/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2610 - accuracy: 0.9149 - val_loss: 0.2622 - val_accuracy: 0.9068\n",
            "Epoch 19/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.9220 - val_loss: 0.2590 - val_accuracy: 0.9037\n",
            "Epoch 20/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.9167 - val_loss: 0.2558 - val_accuracy: 0.9037\n",
            "Epoch 21/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2768 - accuracy: 0.9067 - val_loss: 0.2528 - val_accuracy: 0.9099\n",
            "Epoch 22/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.9078 - val_loss: 0.2498 - val_accuracy: 0.9068\n",
            "Epoch 23/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2393 - accuracy: 0.9210 - val_loss: 0.2480 - val_accuracy: 0.9099\n",
            "Epoch 24/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2277 - accuracy: 0.9215 - val_loss: 0.2455 - val_accuracy: 0.9099\n",
            "Epoch 25/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.9094 - val_loss: 0.2430 - val_accuracy: 0.9099\n",
            "Epoch 26/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.9045 - val_loss: 0.2411 - val_accuracy: 0.9130\n",
            "Epoch 27/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.9115 - val_loss: 0.2399 - val_accuracy: 0.9099\n",
            "Epoch 28/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.9144 - val_loss: 0.2382 - val_accuracy: 0.9099\n",
            "Epoch 29/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2303 - accuracy: 0.9232 - val_loss: 0.2364 - val_accuracy: 0.9130\n",
            "Epoch 30/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.9113 - val_loss: 0.2353 - val_accuracy: 0.9130\n",
            "Epoch 31/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2421 - accuracy: 0.9140 - val_loss: 0.2346 - val_accuracy: 0.9099\n",
            "Epoch 32/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9158 - val_loss: 0.2332 - val_accuracy: 0.9099\n",
            "Epoch 33/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2414 - accuracy: 0.9118 - val_loss: 0.2325 - val_accuracy: 0.9099\n",
            "Epoch 34/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.9131 - val_loss: 0.2314 - val_accuracy: 0.9099\n",
            "Epoch 35/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2414 - accuracy: 0.9139 - val_loss: 0.2308 - val_accuracy: 0.9099\n",
            "Epoch 36/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.9202 - val_loss: 0.2305 - val_accuracy: 0.9099\n",
            "Epoch 37/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.9196 - val_loss: 0.2290 - val_accuracy: 0.9130\n",
            "Epoch 38/200\n",
            "91/91 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.9153 - val_loss: 0.2287 - val_accuracy: 0.9161\n",
            "Epoch 39/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.9098 - val_loss: 0.2281 - val_accuracy: 0.9130\n",
            "Epoch 40/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.9140 - val_loss: 0.2276 - val_accuracy: 0.9193\n",
            "Epoch 41/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.9114 - val_loss: 0.2275 - val_accuracy: 0.9193\n",
            "Epoch 42/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.9153 - val_loss: 0.2268 - val_accuracy: 0.9193\n",
            "Epoch 43/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2303 - accuracy: 0.9202 - val_loss: 0.2267 - val_accuracy: 0.9193\n",
            "Epoch 44/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2378 - accuracy: 0.9135 - val_loss: 0.2263 - val_accuracy: 0.9224\n",
            "Epoch 45/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.9104 - val_loss: 0.2258 - val_accuracy: 0.9317\n",
            "Epoch 46/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9225 - val_loss: 0.2255 - val_accuracy: 0.9317\n",
            "Epoch 47/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2400 - accuracy: 0.9108 - val_loss: 0.2254 - val_accuracy: 0.9317\n",
            "Epoch 48/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.9218 - val_loss: 0.2252 - val_accuracy: 0.9317\n",
            "Epoch 49/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.9107 - val_loss: 0.2250 - val_accuracy: 0.9317\n",
            "Epoch 50/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2297 - accuracy: 0.9213 - val_loss: 0.2247 - val_accuracy: 0.9317\n",
            "Epoch 51/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2554 - accuracy: 0.9130 - val_loss: 0.2246 - val_accuracy: 0.9317\n",
            "Epoch 52/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9222 - val_loss: 0.2242 - val_accuracy: 0.9317\n",
            "Epoch 53/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9228 - val_loss: 0.2241 - val_accuracy: 0.9317\n",
            "Epoch 54/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.9237 - val_loss: 0.2239 - val_accuracy: 0.9317\n",
            "Epoch 55/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2213 - accuracy: 0.9275 - val_loss: 0.2237 - val_accuracy: 0.9317\n",
            "Epoch 56/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2353 - accuracy: 0.9180 - val_loss: 0.2238 - val_accuracy: 0.9317\n",
            "Epoch 57/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2379 - accuracy: 0.9103 - val_loss: 0.2236 - val_accuracy: 0.9317\n",
            "Epoch 58/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2206 - accuracy: 0.9256 - val_loss: 0.2238 - val_accuracy: 0.9317\n",
            "Epoch 59/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.9126 - val_loss: 0.2234 - val_accuracy: 0.9317\n",
            "Epoch 60/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2296 - accuracy: 0.9281 - val_loss: 0.2234 - val_accuracy: 0.9317\n",
            "Epoch 61/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.9162 - val_loss: 0.2232 - val_accuracy: 0.9317\n",
            "Epoch 62/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.9220 - val_loss: 0.2233 - val_accuracy: 0.9317\n",
            "Epoch 63/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.9215 - val_loss: 0.2230 - val_accuracy: 0.9317\n",
            "Epoch 64/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2271 - accuracy: 0.9315 - val_loss: 0.2232 - val_accuracy: 0.9317\n",
            "Epoch 65/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2106 - accuracy: 0.9267 - val_loss: 0.2228 - val_accuracy: 0.9317\n",
            "Epoch 66/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.9226 - val_loss: 0.2230 - val_accuracy: 0.9317\n",
            "Epoch 67/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9242 - val_loss: 0.2227 - val_accuracy: 0.9348\n",
            "Epoch 68/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9251 - val_loss: 0.2224 - val_accuracy: 0.9348\n",
            "Epoch 69/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.9188 - val_loss: 0.2228 - val_accuracy: 0.9317\n",
            "Epoch 70/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.9217 - val_loss: 0.2226 - val_accuracy: 0.9348\n",
            "Epoch 71/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9212 - val_loss: 0.2228 - val_accuracy: 0.9348\n",
            "Epoch 72/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.9128 - val_loss: 0.2225 - val_accuracy: 0.9348\n",
            "Epoch 73/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2145 - accuracy: 0.9296 - val_loss: 0.2224 - val_accuracy: 0.9348\n",
            "Epoch 74/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9278 - val_loss: 0.2220 - val_accuracy: 0.9348\n",
            "Epoch 75/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2258 - accuracy: 0.9207 - val_loss: 0.2223 - val_accuracy: 0.9348\n",
            "Epoch 76/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9229 - val_loss: 0.2223 - val_accuracy: 0.9348\n",
            "Epoch 77/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2254 - accuracy: 0.9215 - val_loss: 0.2224 - val_accuracy: 0.9348\n",
            "Epoch 78/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9190 - val_loss: 0.2221 - val_accuracy: 0.9348\n",
            "Epoch 79/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2106 - accuracy: 0.9245 - val_loss: 0.2223 - val_accuracy: 0.9348\n",
            "Epoch 80/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.9199 - val_loss: 0.2223 - val_accuracy: 0.9348\n",
            "Epoch 81/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2142 - accuracy: 0.9223 - val_loss: 0.2224 - val_accuracy: 0.9348\n",
            "Epoch 82/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.9230 - val_loss: 0.2224 - val_accuracy: 0.9348\n",
            "Epoch 83/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2215 - accuracy: 0.9187 - val_loss: 0.2221 - val_accuracy: 0.9348\n",
            "Epoch 84/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9245 - val_loss: 0.2222 - val_accuracy: 0.9348\n",
            "Epoch 85/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2113 - accuracy: 0.9243 - val_loss: 0.2218 - val_accuracy: 0.9348\n",
            "Epoch 86/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9281 - val_loss: 0.2218 - val_accuracy: 0.9348\n",
            "Epoch 87/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2313 - accuracy: 0.9198 - val_loss: 0.2218 - val_accuracy: 0.9348\n",
            "Epoch 88/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.9253 - val_loss: 0.2217 - val_accuracy: 0.9348\n",
            "Epoch 89/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2100 - accuracy: 0.9226 - val_loss: 0.2221 - val_accuracy: 0.9348\n",
            "Epoch 90/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.9196 - val_loss: 0.2219 - val_accuracy: 0.9348\n",
            "Epoch 91/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.9262 - val_loss: 0.2217 - val_accuracy: 0.9348\n",
            "Epoch 92/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2105 - accuracy: 0.9224 - val_loss: 0.2219 - val_accuracy: 0.9348\n",
            "Epoch 93/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2126 - accuracy: 0.9278 - val_loss: 0.2216 - val_accuracy: 0.9348\n",
            "Epoch 94/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.9278 - val_loss: 0.2220 - val_accuracy: 0.9348\n",
            "Epoch 95/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2248 - accuracy: 0.9225 - val_loss: 0.2219 - val_accuracy: 0.9348\n",
            "Epoch 96/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.9264 - val_loss: 0.2220 - val_accuracy: 0.9348\n",
            "Epoch 97/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9269 - val_loss: 0.2219 - val_accuracy: 0.9348\n",
            "Epoch 98/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.9237 - val_loss: 0.2220 - val_accuracy: 0.9348\n",
            "Epoch 99/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2097 - accuracy: 0.9257 - val_loss: 0.2220 - val_accuracy: 0.9348\n",
            "Epoch 100/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2142 - accuracy: 0.9205 - val_loss: 0.2220 - val_accuracy: 0.9348\n",
            "Epoch 101/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.9289 - val_loss: 0.2217 - val_accuracy: 0.9348\n",
            "Epoch 102/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2115 - accuracy: 0.9299 - val_loss: 0.2217 - val_accuracy: 0.9348\n",
            "Epoch 103/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9126 - val_loss: 0.2221 - val_accuracy: 0.9317\n",
            "Epoch 104/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9263 - val_loss: 0.2218 - val_accuracy: 0.9317\n",
            "Epoch 105/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2083 - accuracy: 0.9274 - val_loss: 0.2219 - val_accuracy: 0.9348\n",
            "Epoch 106/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2149 - accuracy: 0.9213 - val_loss: 0.2218 - val_accuracy: 0.9348\n",
            "Epoch 107/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.9203 - val_loss: 0.2218 - val_accuracy: 0.9348\n",
            "Epoch 108/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.9335 - val_loss: 0.2219 - val_accuracy: 0.9348\n",
            "Epoch 109/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.9188 - val_loss: 0.2217 - val_accuracy: 0.9286\n",
            "Epoch 110/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.9210 - val_loss: 0.2220 - val_accuracy: 0.9286\n",
            "Epoch 111/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9149 - val_loss: 0.2220 - val_accuracy: 0.9317\n",
            "Epoch 112/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2258 - accuracy: 0.9147 - val_loss: 0.2218 - val_accuracy: 0.9286\n",
            "Epoch 113/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9187 - val_loss: 0.2217 - val_accuracy: 0.9317\n",
            "Epoch 114/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2063 - accuracy: 0.9269 - val_loss: 0.2218 - val_accuracy: 0.9286\n",
            "Epoch 115/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.9164 - val_loss: 0.2218 - val_accuracy: 0.9317\n",
            "Epoch 116/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2091 - accuracy: 0.9240 - val_loss: 0.2218 - val_accuracy: 0.9317\n",
            "Epoch 117/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9327 - val_loss: 0.2217 - val_accuracy: 0.9317\n",
            "Epoch 118/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9199 - val_loss: 0.2216 - val_accuracy: 0.9286\n",
            "Epoch 119/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 0.9226 - val_loss: 0.2215 - val_accuracy: 0.9317\n",
            "Epoch 120/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.9136 - val_loss: 0.2218 - val_accuracy: 0.9286\n",
            "Epoch 121/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.9219 - val_loss: 0.2218 - val_accuracy: 0.9286\n",
            "Epoch 122/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.9156 - val_loss: 0.2216 - val_accuracy: 0.9286\n",
            "Epoch 123/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9231 - val_loss: 0.2217 - val_accuracy: 0.9286\n",
            "Epoch 124/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9211 - val_loss: 0.2217 - val_accuracy: 0.9286\n",
            "Epoch 125/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2108 - accuracy: 0.9300 - val_loss: 0.2219 - val_accuracy: 0.9286\n",
            "Epoch 126/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9261 - val_loss: 0.2216 - val_accuracy: 0.9286\n",
            "Epoch 127/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9209 - val_loss: 0.2216 - val_accuracy: 0.9286\n",
            "Epoch 128/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9255 - val_loss: 0.2219 - val_accuracy: 0.9286\n",
            "Epoch 129/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2004 - accuracy: 0.9255 - val_loss: 0.2214 - val_accuracy: 0.9286\n",
            "Epoch 130/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.1949 - accuracy: 0.9328 - val_loss: 0.2214 - val_accuracy: 0.9286\n",
            "Epoch 131/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.9338 - val_loss: 0.2213 - val_accuracy: 0.9286\n",
            "Epoch 132/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.9207 - val_loss: 0.2216 - val_accuracy: 0.9286\n",
            "Epoch 133/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2160 - accuracy: 0.9215 - val_loss: 0.2215 - val_accuracy: 0.9286\n",
            "Epoch 134/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2183 - accuracy: 0.9246 - val_loss: 0.2215 - val_accuracy: 0.9286\n",
            "Epoch 135/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9282 - val_loss: 0.2212 - val_accuracy: 0.9286\n",
            "Epoch 136/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2230 - accuracy: 0.9217 - val_loss: 0.2216 - val_accuracy: 0.9286\n",
            "Epoch 137/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2368 - accuracy: 0.9129 - val_loss: 0.2216 - val_accuracy: 0.9286\n",
            "Epoch 138/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2285 - accuracy: 0.9190 - val_loss: 0.2216 - val_accuracy: 0.9286\n",
            "Epoch 139/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2182 - accuracy: 0.9177 - val_loss: 0.2215 - val_accuracy: 0.9286\n",
            "Epoch 140/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2007 - accuracy: 0.9322 - val_loss: 0.2214 - val_accuracy: 0.9286\n",
            "Epoch 141/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2199 - accuracy: 0.9236 - val_loss: 0.2214 - val_accuracy: 0.9286\n",
            "Epoch 142/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2217 - accuracy: 0.9189 - val_loss: 0.2214 - val_accuracy: 0.9286\n",
            "Epoch 143/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2166 - accuracy: 0.9240 - val_loss: 0.2214 - val_accuracy: 0.9286\n",
            "Epoch 144/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.9156 - val_loss: 0.2212 - val_accuracy: 0.9286\n",
            "Epoch 145/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.9302 - val_loss: 0.2212 - val_accuracy: 0.9286\n",
            "Epoch 146/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.9326 - val_loss: 0.2215 - val_accuracy: 0.9286\n",
            "Epoch 147/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9268 - val_loss: 0.2211 - val_accuracy: 0.9286\n",
            "Epoch 148/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.9192 - val_loss: 0.2214 - val_accuracy: 0.9286\n",
            "Epoch 149/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2122 - accuracy: 0.9233 - val_loss: 0.2213 - val_accuracy: 0.9286\n",
            "Epoch 150/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.9191 - val_loss: 0.2214 - val_accuracy: 0.9286\n",
            "Epoch 151/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9239 - val_loss: 0.2212 - val_accuracy: 0.9286\n",
            "Epoch 152/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.9271 - val_loss: 0.2213 - val_accuracy: 0.9286\n",
            "Epoch 153/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2163 - accuracy: 0.9237 - val_loss: 0.2212 - val_accuracy: 0.9286\n",
            "Epoch 154/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9289 - val_loss: 0.2212 - val_accuracy: 0.9286\n",
            "Epoch 155/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2021 - accuracy: 0.9219 - val_loss: 0.2212 - val_accuracy: 0.9286\n",
            "Epoch 156/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2026 - accuracy: 0.9273 - val_loss: 0.2211 - val_accuracy: 0.9286\n",
            "Epoch 157/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9218 - val_loss: 0.2210 - val_accuracy: 0.9286\n",
            "Epoch 158/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2122 - accuracy: 0.9206 - val_loss: 0.2210 - val_accuracy: 0.9286\n",
            "Epoch 159/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.9222 - val_loss: 0.2212 - val_accuracy: 0.9286\n",
            "Epoch 160/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.9241 - val_loss: 0.2214 - val_accuracy: 0.9286\n",
            "Epoch 161/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.9211 - val_loss: 0.2212 - val_accuracy: 0.9286\n",
            "Epoch 162/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2309 - accuracy: 0.9168 - val_loss: 0.2214 - val_accuracy: 0.9286\n",
            "Epoch 163/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.9254 - val_loss: 0.2210 - val_accuracy: 0.9286\n",
            "Epoch 164/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9327 - val_loss: 0.2210 - val_accuracy: 0.9286\n",
            "Epoch 165/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.1969 - accuracy: 0.9290 - val_loss: 0.2213 - val_accuracy: 0.9286\n",
            "Epoch 166/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9162 - val_loss: 0.2210 - val_accuracy: 0.9286\n",
            "Epoch 167/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2143 - accuracy: 0.9231 - val_loss: 0.2210 - val_accuracy: 0.9286\n",
            "Epoch 168/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2070 - accuracy: 0.9222 - val_loss: 0.2207 - val_accuracy: 0.9286\n",
            "Epoch 169/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2004 - accuracy: 0.9253 - val_loss: 0.2209 - val_accuracy: 0.9286\n",
            "Epoch 170/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9257 - val_loss: 0.2213 - val_accuracy: 0.9286\n",
            "Epoch 171/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.9292 - val_loss: 0.2212 - val_accuracy: 0.9286\n",
            "Epoch 172/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.9216 - val_loss: 0.2212 - val_accuracy: 0.9286\n",
            "Epoch 173/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.9343 - val_loss: 0.2213 - val_accuracy: 0.9286\n",
            "Epoch 174/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2264 - accuracy: 0.9248 - val_loss: 0.2210 - val_accuracy: 0.9286\n",
            "Epoch 175/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.9220 - val_loss: 0.2213 - val_accuracy: 0.9286\n",
            "Epoch 176/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2143 - accuracy: 0.9223 - val_loss: 0.2212 - val_accuracy: 0.9286\n",
            "Epoch 177/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2176 - accuracy: 0.9224 - val_loss: 0.2214 - val_accuracy: 0.9286\n",
            "Epoch 178/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 0.9252 - val_loss: 0.2212 - val_accuracy: 0.9286\n",
            "Epoch 179/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9320 - val_loss: 0.2210 - val_accuracy: 0.9286\n",
            "Epoch 180/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9248 - val_loss: 0.2211 - val_accuracy: 0.9286\n",
            "Epoch 181/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 0.9262 - val_loss: 0.2212 - val_accuracy: 0.9286\n",
            "Epoch 182/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.9289 - val_loss: 0.2209 - val_accuracy: 0.9286\n",
            "Epoch 183/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.9199 - val_loss: 0.2209 - val_accuracy: 0.9286\n",
            "Epoch 184/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9247 - val_loss: 0.2211 - val_accuracy: 0.9286\n",
            "Epoch 185/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.9286 - val_loss: 0.2212 - val_accuracy: 0.9286\n",
            "Epoch 186/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9285 - val_loss: 0.2211 - val_accuracy: 0.9286\n",
            "Epoch 187/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2100 - accuracy: 0.9239 - val_loss: 0.2209 - val_accuracy: 0.9286\n",
            "Epoch 188/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9219 - val_loss: 0.2210 - val_accuracy: 0.9286\n",
            "Epoch 189/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2137 - accuracy: 0.9180 - val_loss: 0.2213 - val_accuracy: 0.9286\n",
            "Epoch 190/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9228 - val_loss: 0.2210 - val_accuracy: 0.9286\n",
            "Epoch 191/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.9223 - val_loss: 0.2208 - val_accuracy: 0.9286\n",
            "Epoch 192/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9243 - val_loss: 0.2209 - val_accuracy: 0.9286\n",
            "Epoch 193/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9266 - val_loss: 0.2207 - val_accuracy: 0.9286\n",
            "Epoch 194/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9265 - val_loss: 0.2210 - val_accuracy: 0.9286\n",
            "Epoch 195/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9319 - val_loss: 0.2209 - val_accuracy: 0.9286\n",
            "Epoch 196/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9218 - val_loss: 0.2211 - val_accuracy: 0.9286\n",
            "Epoch 197/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2151 - accuracy: 0.9227 - val_loss: 0.2209 - val_accuracy: 0.9286\n",
            "Epoch 198/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9221 - val_loss: 0.2210 - val_accuracy: 0.9286\n",
            "Epoch 199/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.9242 - val_loss: 0.2211 - val_accuracy: 0.9286\n",
            "Epoch 200/200\n",
            "91/91 [==============================] - 0s 2ms/step - loss: 0.2162 - accuracy: 0.9145 - val_loss: 0.2214 - val_accuracy: 0.9286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP6xxGQzuGdB",
        "outputId": "bf02e11e-bb10-4604-97e3-bc8e4d1d6360"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 1)                 58        \n",
            "=================================================================\n",
            "Total params: 58\n",
            "Trainable params: 58\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "dYSXL2BewJcr",
        "outputId": "58979fa2-a4df-4af3-a825-e048b757e06e"
      },
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(a.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSDYw2bYZhQx"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXh0MX_duwY_",
        "outputId": "d161548e-3155-44e0-8596-2cb15041d075"
      },
      "source": [
        "# Test, Loss and accuracy\n",
        "loss_and_metrics = model.evaluate(X_test, y_test)\n",
        "print('Loss = ',loss_and_metrics[0])\n",
        "print('Accuracy = ',loss_and_metrics[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44/44 [==============================] - 0s 1ms/step - loss: 0.2183 - accuracy: 0.9225\n",
            "Loss =  0.2183072865009308\n",
            "Accuracy =  0.9225199222564697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lKOhwt_XLI_",
        "outputId": "2bef91f8-c721-406f-d4a3-3ebaa4d11895"
      },
      "source": [
        "pred=model.predict_classes(X_test)\n",
        "pred=[i for x in pred for i in x]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "1vLdr0PxS5pL",
        "outputId": "9860f0a0-ca6d-4f61-c79c-91fbb56a278b"
      },
      "source": [
        "cm = confusion_matrix(y_test,pred)\n",
        "sns.heatmap(cm,annot=True,fmt=\"d\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fba4c8c68d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}